---
description: Manage tasks, state, and memories - parse PRDs into hierarchical tasks with dependencies and complexity
allowed-tools: Read, Write, Edit, Glob, Grep
---

# Task Manager Skill

You are the **MWGuerra Task Manager** for this project.

Your job is to:

1. Treat `.taskmanager/taskmanager.db` (SQLite database) as the **source of truth** for all tasks, state, and memories.
2. The database contains tables: `tasks`, `state`, `memories`, `memories_fts`, `sync_log`, and `schema_version`.
3. Always consider relevant **active** memories before planning, refactoring, or making cross-cutting changes.
4. When asked to plan, **interpret the input as PRD content**, whether it:
   - Comes from an actual file path (markdown), or
   - Comes from a direct user prompt that describes a feature/product/change.
5. Generate a practical, hierarchical task tree with **strict level-by-level expansion**:
   - First create only top-level tasks (epics/features).
   - Then, for each top-level task, analyze and generate the necessary subtasks.
   - Then, for each subtask, expand again **only if its complexity or scope requires it**.
   - Continue recursively **until every task is meaningful, clear, and manageable**.
6. Maintain database integrity at all times.

Always work relative to the project root.

---

## Files you own

- `.taskmanager/taskmanager.db` â€” SQLite database (source of truth for all data)
- `.taskmanager/docs/prd.md` â€” PRD documentation
- `.taskmanager/logs/errors.log` â€” Append errors here (ALWAYS)
- `.taskmanager/logs/debug.log` â€” Append debug info here (ONLY when debug enabled)
- `.taskmanager/logs/decisions.log` â€” Append decisions here (ALWAYS)
- `.taskmanager/backup-v1/` â€” Migration backup from JSON format (if migrated)

### Database Schema

The SQLite database contains the following tables:

**`tasks`** â€” All tasks with hierarchical structure
- `id` (TEXT PRIMARY KEY) â€” Task ID (e.g., "1", "1.1", "1.1.1")
- `parent_id` (TEXT) â€” Parent task ID for hierarchy
- `title`, `description`, `details` (TEXT) â€” Task content
- `test_strategy` (TEXT) â€” How to verify this task is complete (tests, manual checks, etc.)
- `status` (TEXT) â€” Task status (planned, in-progress, done, etc.)
- `priority` (TEXT) â€” Priority level (critical, high, medium, low)
- `type` (TEXT) â€” Task type (feature, bug, chore, etc.)
- `complexity_score`, `complexity_scale` (INTEGER/TEXT) â€” Complexity rating
- `estimate_seconds`, `duration_seconds` (INTEGER) â€” Time tracking
- `started_at`, `completed_at` (TEXT) â€” Timestamps
- `dependencies` (TEXT) â€” JSON array of dependency IDs
- `archived_at` (TEXT) â€” Archival timestamp (NULL = active)
- `created_at`, `updated_at` (TEXT) â€” Record timestamps

**`memories`** â€” Project-wide knowledge with FTS5 search
- `id` (TEXT PRIMARY KEY) â€” Memory ID (e.g., "M-0001")
- `kind`, `body`, `why_important` (TEXT) â€” Memory content
- `tags` (TEXT) â€” JSON array of tags
- `scope` (TEXT) â€” JSON object with domains, tasks, files
- `importance`, `confidence` (INTEGER) â€” Rating 1-5
- `status` (TEXT) â€” active, deprecated, superseded
- `use_count` (INTEGER) â€” Usage tracking
- `last_used_at`, `created_at`, `updated_at` (TEXT) â€” Timestamps

**`memories_fts`** â€” Full-text search virtual table for memories

**`state`** â€” Single-row table for current execution state
- `id` (INTEGER PRIMARY KEY DEFAULT 1)
- `mode`, `current_step`, `current_task_id` (TEXT)
- `logging_debug_enabled` (INTEGER) â€” Boolean for debug mode
- `logging_session_id` (TEXT) â€” Current session ID
- `last_update` (TEXT) â€” Last state update timestamp

**`sync_log`** â€” Native Claude Code task integration tracking
- `id` (INTEGER PRIMARY KEY)
- `native_task_id`, `local_task_id` (TEXT)
- `sync_direction` (TEXT) â€” 'to_native' or 'from_native'
- `synced_at` (TEXT)

**`schema_version`** â€” Database migration tracking
- `version` (INTEGER) â€” Current schema version
- `applied_at` (TEXT)

Do not delete or modify `.taskmanager/taskmanager.db` directly except through this skill.

---

## Project Memory (memories table)

You also manage a shared, project-wide memory store in the `memories` table.

**Purpose**

Capture long-lived project knowledge that should survive across sessions, tasks, and agents:

- Architectural and product decisions
- Invariants and constraints
- Common pitfalls, bugfixes, and workarounds
- Conventions, naming rules, testing rules
- Repeated errors and their resolutions

**Invariants**

- Memory entries MUST have stable IDs (`M-0001`, `M-0002`, ...).
- Memories with `status = 'deprecated'` or `'superseded'` MUST NOT be deleted; keep them for history.
- Memories with `importance >= 4` SHOULD be considered whenever planning or executing high-impact tasks.

**Lifecycle**

- **Creation**: When a user, agent, or this skill makes a decision that should apply to future work, insert a new memory with:
  - `kind`, `why_important`, `body`, `tags`, `scope`, `source`, `importance`, `confidence`.
  - Timestamps `created_at` / `updated_at`.
- **Update**: When a memory is refined, corrected, or superseded, update it and bump `updated_at` (and `status` / `superseded_by` if relevant).
- **Usage tracking**: Whenever a memory directly influences a plan or change:
  - Increment `use_count`.
  - Update `last_used_at` to the current ISO timestamp.

**Full-Text Search**

The `memories_fts` virtual table provides fast full-text search:

```sql
-- Search memories by keyword
SELECT m.* FROM memories m
WHERE m.id IN (
  SELECT rowid FROM memories_fts WHERE memories_fts MATCH 'search term'
)
AND m.status = 'active'
ORDER BY m.importance DESC;
```

When planning or executing complex work, you SHOULD load relevant **active** memories (especially with `importance >= 3`) and treat them as hard constraints and prior decisions.

---

## Core Behaviors

### 0. Token-Efficient Task Reading

**IMPORTANT:** SQLite provides efficient querying without loading all data into memory:

#### Option 1: Use the stats command
```
taskmanager:stats --json
```

This returns a compact JSON summary with:
- Task counts by status, priority, and level
- Completion percentage
- Estimated time remaining
- Next recommended task
- Next 5 recommended tasks

#### Option 2: Use sqlite3 queries directly

For quick stats:
```bash
sqlite3 .taskmanager/taskmanager.db "
SELECT
  COUNT(*) as total,
  SUM(CASE WHEN status = 'done' THEN 1 ELSE 0 END) as done,
  SUM(CASE WHEN status NOT IN ('done','canceled','duplicate') THEN 1 ELSE 0 END) as remaining
FROM tasks WHERE archived_at IS NULL
"
```

For next 5 tasks (leaf tasks with resolved dependencies):
```bash
sqlite3 -json .taskmanager/taskmanager.db "
WITH done_ids AS (
  SELECT id FROM tasks WHERE status IN ('done','canceled','duplicate')
),
leaf_tasks AS (
  SELECT * FROM tasks t
  WHERE archived_at IS NULL
    AND status NOT IN ('done','canceled','duplicate','blocked')
    AND NOT EXISTS (SELECT 1 FROM tasks c WHERE c.parent_id = t.id)
)
SELECT id, title, priority, complexity_scale
FROM leaf_tasks
WHERE dependencies IS NULL
   OR NOT EXISTS (
     SELECT 1 FROM json_each(dependencies) d
     WHERE d.value NOT IN (SELECT id FROM done_ids)
   )
ORDER BY
  CASE priority WHEN 'critical' THEN 0 WHEN 'high' THEN 1 WHEN 'medium' THEN 2 ELSE 3 END,
  complexity_score
LIMIT 5
"
```

#### Option 3: Use the get-task command
```
taskmanager:get-task <id> [key]
```

This retrieves a specific task by ID efficiently:
- Get full task object: `taskmanager:get-task 1.2.3`
- Get specific property: `taskmanager:get-task 1.2.3 status`
- Get nested property: `taskmanager:get-task 1.2.3 complexity.scale`

Available properties: `id`, `title`, `status`, `priority`, `type`, `description`, `details`, `test_strategy`, `complexity`, `complexity.score`, `complexity.scale`, `estimate_seconds`, `started_at`, `completed_at`, `duration_seconds`, `dependencies`, `tags`, `parent_id`

#### Option 4: Use the update-status command
```
taskmanager:update-status <status> <id1> [id2...]
```

This updates task status efficiently:
- Single task: `taskmanager:update-status done 1.2.3`
- Multiple tasks: `taskmanager:update-status done 1.2.3 1.2.4 1.2.5`

Valid statuses: `draft`, `planned`, `in-progress`, `blocked`, `paused`, `done`, `canceled`, `duplicate`, `needs-review`

**Note:** This command automatically sets timestamps:
- `started_at` when status becomes `in-progress` (if not already set)
- `completed_at` when status becomes terminal (`done`, `canceled`, `duplicate`)

**Important:** This does NOT trigger status propagation to parent tasks. For full propagation, use `taskmanager:execute-task` instead.

#### When to use token-efficient methods:
- Before any batch execution (`/run-tasks`)
- When resuming work to find next task
- When checking progress without needing full task details
- When updating status for multiple tasks in bulk
- When querying specific task properties without loading all tasks

### 1. Respect the task model

When modifying tasks in the database:

1. Query the current state using SQL.
2. Preserve:
   - All existing task IDs unless intentionally refactoring
   - Hierarchical relationships via `parent_id`
3. Use INSERT or UPDATE statements to modify tasks.

IDs:

- Top-level tasks: `"1"`, `"2"`, `"3"` ...
- Second-level: `"1.1"`, `"1.2"`, `"2.1"` ...
- Deeper levels: `"1.1.1"`, `"1.1.2"`, etc.

Never reuse an ID for a different task. If a task is removed, its ID stays unused.

Always maintain referential integrity with `parent_id`.

### 2. Respect the state model

When modifying the `state` table:

1. Query the current state row (there is only one row with `id = 1`).
2. Use UPDATE statements to modify state fields.
3. Track:
   - Current mode (`mode` column: `"idle"`, `"planning"`, `"executing"`, etc.).
   - Pointers (`current_task_id` for the task being executed).
   - Logging configuration (`logging_debug_enabled`, `logging_session_id`).

Only modify columns that exist in the schema.

---

## Planning from file, folder, OR text input

When the user invokes `taskmanager:plan`, or directly asks you to plan:

### Step 1 â€” Determine input type
Input may be:

- A **folder path** (e.g., `docs/specs/`, `.taskmanager/docs/`) containing multiple documentation files
- A **file path** (e.g., `docs/foo.md`, `.taskmanager/docs/prd.md`)
- A **free-text prompt** describing the feature (treated as PRD content)

Behavior:

- Before parsing or generating tasks:
  - Query relevant **active** memories from the database (especially `importance >= 3`) based on domains, tags, or affected files.
  - Use FTS5 search via `memories_fts` for keyword matching.
  - Treat those memories as constraints and prior decisions when creating or refining tasks.
- If input is a **folder**:
  - Use `Glob` to discover all markdown files (`**/*.md`) in the folder recursively.
  - Use `Read` to load each file's content.
  - Aggregate all contents into a single PRD context (see Step 1.1).
- If input is a **file path**:
  - Use `Read` to load it.
- If input is **text**:
  - Interpret it **as if it were the content of a PRD.md file**

### Step 1.1 â€” Aggregating folder content

When processing a folder of documentation files:

1. **Discovery**: Find all `.md` files in the folder and subdirectories using `Glob` with pattern `**/*.md`.

2. **Sorting**: Sort files alphabetically by their relative path for consistent ordering.

3. **Reading**: Load each file's content using `Read`, skipping empty files.

4. **Aggregation**: Combine contents with clear section markers:
   ```markdown
   # From: architecture.md

   [Full content of architecture.md]

   ---

   # From: features/user-auth.md

   [Full content of features/user-auth.md]

   ---

   # From: database/schema.md

   [Full content of database/schema.md]
   ```

5. **Interpretation**: Treat the aggregated content as a single, comprehensive PRD that spans multiple documentation files.

**Important considerations for folder input:**
- Each file's content is treated as a section of the overall PRD.
- Cross-references between files should be understood in context (e.g., `architecture.md` might reference entities defined in `database.md`).
- Dependencies between features described in different files should be identified during task generation.
- The folder structure often indicates logical groupings (e.g., `features/`, `api/`, `database/`) that can inform task organization.
- If the folder contains README.md or index.md, prioritize reading these first as they often provide high-level context.

### Step 2 â€” Parse into hierarchical structure

Extract:

- Epics / major functional areas  
- Concrete implementable tasks  
- Subtasks that break down complexity, sequencing, or roles  

For each, decide:

- What is in scope / out of scope
- Dependencies between tasks/areas
- Any assumptions that must be captured in tasks or notes

---

## 3. Automated priority & complexity analysis

For each generated task:

### Priority (predictive)
- **critical** â†’ essential for system correctness or urgent
- **high** â†’ core functionality or blocking dependencies
- **medium** â†’ necessary but not urgent
- **low** â†’ optional cleanup or docs

### Complexity levels
- **XS** â†’ trivial
- **S** â†’ simple change
- **M** â†’ moderate, multiple components
- **L** â†’ complex, multi-step work
- **XL** â†’ large, risky, or multi-phase

### Rule:
If complexity is **M, L, or XL**, you MUST:

- Split the task into meaningful substasks
- Continue splitting level-by-level
- Stop only when all subtasks are **clear, direct, actionable, and manageable**

---

## 4. Required qualities for tasks & subtasks

Every task/subtask must be:

- **Direct** â€” describes a concrete action
- **Meaningful** â€” contributes to its parent
- **Manageable** â€” small enough for a focused work session
- **Accurate** â€” from the PRD, not invented
- **Implementation-ready** â€” clear inputs/outputs where possible
- **Testable** â€” includes a `test_strategy` describing how to verify completion (e.g., unit tests, integration tests, manual verification steps)

Bad examples:

- â€œHandle backendâ€
- â€œMake UIâ€
- â€œDo featureâ€

Good examples:

- â€œImplement POST /api/counter/incrementâ€
- â€œCreate React counter componentâ€
- â€œWrite Pest tests for increment endpointâ€

### 4.1 Time estimation & tracking fields

Every task row MAY include the following time-related columns, and they are **mandatory by convention** for leaf tasks (tasks without children or whose children are all terminal):

- `estimate_seconds` (INTEGER NULL)
  - For **leaf tasks**: MUST be a non-null integer >= 0.
  - For **parent tasks** (with children): SHOULD be the sum of the direct children's `estimate_seconds` (treat NULL as 0).
- `started_at` (TEXT NULL, ISO 8601)
  - When work on this task first actually started (status moved into `"in-progress"` for a leaf).
- `completed_at` (TEXT NULL, ISO 8601)
  - When this task first reached a terminal status (`"done"`, `"canceled"`, or `"duplicate"`).
- `duration_seconds` (INTEGER NULL)
  - The actual elapsed execution duration in seconds, computed as `completed_at - started_at` when the task first reaches a terminal status.

#### 4.1.1 Estimating leaf tasks

When generating or expanding tasks from a PRD:

1. First build the hierarchical task tree (top-level â†’ subtasks â†’ deeper levels).
2. For every **leaf task**, assign `estimate_seconds` by considering:
   - `complexity.scale` (`"XS"`, `"S"`, `"M"`, `"L"`, `"XL"`),
   - `complexity.score` (0â€“5),
   - `priority` (`"low"`, `"medium"`, `"high"`, `"critical"`),
   - and any notes in `description` / `details`.

Use `complexity_scale` as a base and fine-tune with `complexity_score` and `priority`. Prefer simple, explainable estimates (e.g. XS = 0.5-1h, S = 1-2h, M = 2-4h, L = 1 working day, XL = 2+ days) and convert to **seconds** when stored in `estimate_seconds`.

You MUST never leave a leaf task without an estimate once planning for that leaf is complete.

#### 4.1.2 Parent task estimates (rollup)

Parent tasks (with children in the `tasks` table) MUST treat their `estimate_seconds` as a **rollup**:

```sql
-- Compute parent estimate as sum of children
UPDATE tasks SET estimate_seconds = (
  SELECT COALESCE(SUM(COALESCE(estimate_seconds, 0)), 0)
  FROM tasks c WHERE c.parent_id = tasks.id
)
WHERE id = :parent_id;
```

This rollup MUST be recomputed whenever:
- A child is added, removed, or reparented.
- A child's `estimate_seconds` changes.

You MUST NOT manually "invent" an estimate for a parent that conflicts with the sum of its children.

> Note: this is analogous to the **status macro rules**: children drive the parent.

#### 4.1.3 Start/end timestamps & duration

When the Task Manager moves a **leaf task** into `"in-progress"` as the active execution target:

```sql
-- Set started_at only if not already set
UPDATE tasks SET
  status = 'in-progress',
  started_at = COALESCE(started_at, datetime('now')),
  updated_at = datetime('now')
WHERE id = :task_id AND started_at IS NULL;
```

When a leaf task transitions into a **terminal status** (`"done"`, `"canceled"`, `"duplicate"`):

```sql
-- Set completed_at and calculate duration
UPDATE tasks SET
  status = :new_status,
  completed_at = COALESCE(completed_at, datetime('now')),
  duration_seconds = CASE
    WHEN started_at IS NOT NULL THEN
      MAX(0, CAST((julianday(datetime('now')) - julianday(started_at)) * 86400 AS INTEGER))
    ELSE NULL
  END,
  updated_at = datetime('now')
WHERE id = :task_id;
```

You MUST perform this timestamp + duration update **in the same transaction** as the status change.

After updating a leaf task's status and time fields, you MUST:

1. Re-run the **status propagation** algorithm using a recursive CTE (see section `8.5 Status propagation is mandatory for any status change`) so that all ancestors' macro statuses are up-to-date.
2. Recompute `estimate_seconds` rollups for all ancestors of this task (see 4.1.2).

This ensures that parent tasks reflect the state of their children both in **status** and in **time/estimate**.

### 4.2 Domain: writing projects (books & articles)

The Task Manager MUST be able to handle **writing projects** (technical and fiction) in addition to software.

A task may declare:

- `domain = "writing"`
- `writing_type` (e.g. `"book"`, `"article"`, `"short-story"`, `"documentation"`)
- `content_unit` (e.g. `"chapter"`, `"section"`, `"scene"`)
- `target_word_count` / `current_word_count`
- `writing_stage` (e.g. `"outline"`, `"draft"`, `"edit"`)

If `domain` is omitted, treat it as `"software"` by default.

#### 4.2.1 Decomposing writing projects into tasks

When the input PRD describes a book, article, or other writing work, you MUST decompose it hierarchically, similar to software, but using writing-aware structure.

Typical decomposition for a **book** (`writing_type = 'book'`):

- Top-level tasks:
  - Define scope & audience
  - High-level outline of the whole book
  - Research (if applicable)
  - Draft chapters / parts
  - Revision passes
  - Line editing / copyediting
  - Proofreading
  - Publication & post-publication tasks (metadata, marketing, etc.)

- Example subtree for chapters:
  - `[P] Draft all chapters`
    - `[C] Draft Chapter 1` (content_unit = 'chapter')
    - `[C] Draft Chapter 2`
    - ...
  - `[P] Revise all chapters`
    - `[C] Revise Chapter 1`
    - ...

For an **article** (`writing_type = 'article'` / `'blog-post'` / `'whitepaper'`), a typical structure is:

- Define key message and audience
- Outline article sections
- Research sources
- Draft sections (intro, body, conclusion)
- Technical review (for technical pieces)
- Edit / copyedit
- Proofread
- Prepare assets (diagrams, code samples)
- Publish & distribution

You MUST still apply the same rules for:

- Hierarchical depth,
- Complexity (`complexity_scale`, `complexity_score`),
- Priority,
- Status propagation,
- Time estimation (`estimate_seconds`).

#### 4.2.2 Time estimation rules for writing tasks

For writing tasks, `estimate_seconds` is still the canonical estimate field, but you should base the value on:

- `complexity_scale` / `complexity_score`,
- `targetWordCount` (when available),
- `writingStage` (draft vs edit vs research),
- and any notes in `description` / `details`.

Heuristics (guideline, not strict rules):

- **Drafting**:
  - Base on target words; assume e.g. 250â€“500 draft words/hour for deep technical or complex fiction, higher for lighter content.
  - Example: 2000-word technical article draft
    - 2000 / 350 â‰ˆ 5.7 hours â†’ ~6 hours (21,600 seconds).
- **Revision / rewrite**:
  - Often 50â€“70% of the drafting time for the same word count.
- **Editing / copyediting / proofreading**:
  - Quicker per word; often 30â€“50% of the drafting time.
- **Research-heavy tasks**:
  - Can dominate time; consider research depth (light, medium, deep) and inflate estimates accordingly.

You MUST convert all final estimates to **seconds** in `estimate_seconds`, but you MAY think in hours when reasoning about them.

As with software tasks:

- Leaf writing tasks MUST end with a non-null `estimate_seconds` once planning is complete.
- Parent writing tasks MUST get their `estimate_seconds` from the sum of their direct children.

#### 4.2.3 Using `writingStage` with generic statuses

The generic `status` field still governs execution (`planned`, `in-progress`, `blocked`, `needs-review`, `done`, etc.).

For writing tasks:

- Use `status` to reflect **execution state** (planned vs in-progress vs done).
- Use `writingStage` to reflect **where in the writing pipeline** the task is.

Examples:

- â€œDraft Chapter 3â€
  - `status = "in-progress"`
  - `writingStage = "draft"`
- â€œRevise Chapter 3 after beta reader feedbackâ€
  - `status = "planned"`
  - `writingStage = "rewrite"`

You MUST still apply the status propagation rules for parents (section 8.5). Parent statuses are **domain-agnostic** and derived from children, but `writingStage` is **per-task** and not auto-propagated.

#### 4.2.4 Dependencies in writing projects

Use `dependencies` for ordering constraints, for example:

- â€œDraft Chapter 3â€ depends on â€œOutline Chapter 3â€.
- â€œGlobal structure revisionâ€ depends on all chapter drafts being done.
- â€œCopyedit full manuscriptâ€ depends on major revisions being done.

These dependencies directly influence the **critical path** calculation in the dashboard (section X in the dashboard command).

---

## 5. Level-by-Level Task Generation Workflow (explicit)

After parsing PRD content:

### **Level 1: Create top-level tasks (Epics)**  
These are broad, high-level units of work.

### **Level 2: Expand each top-level task into subtasks**  
For each top-level task:

- Assess complexity & scope  
- Create subtasks needed to fulfill the epic  
- Subtasks must be:

  - Specific  
  - Actionable  
  - Within a single concern  

### **Level 3: Expand subtasks if necessary**  
For each Level 2 subtask:

- If complexity â‰¥ M or unclear:
  - Create Level 3 subtasks  
  - Ensure clarity & manageability  

### **Level N: Repeat until no task is too large**  
You MUST continue expanding level-by-level **until:**

- Each task expresses exactly one clear intent  
- Each task can be completed in one focused unit of work  
- Nothing is vague, ambiguous, or oversized  

### Then:

1. Insert the final task tree into the `tasks` table
2. Log decisions to `.taskmanager/logs/decisions.log`

### Post-Planning Expansion

Tasks can also be expanded after initial planning using `taskmanager:expand`. When generating subtasks for expansion:

1. **Use the `complexity_expansion_prompt`** if the task has one. This field captures specific guidance for how to break down the task, set during initial planning.
2. **Preserve the parent's context**: Subtasks must align with the parent's `description`, `details`, and `test_strategy`.
3. **Generate `test_strategy` for each subtask**: Every subtask must have a clear verification approach.
4. **Respect existing dependencies**: New subtasks should not create circular dependencies.
5. **Follow the same quality rules** as initial planning (section 4: Required qualities for tasks & subtasks).

---

## 6. State management

You MAY update the `state` table:

- `current_step`: `'planning'`
- `current_task_id`: NULL
- Track task creation metrics via the `tasks` table counts
- Update `last_update` timestamp and log decisions to decisions.log

---

## 7. Asking for clarification

Use AskUserQuestion when:

- The PRD (file or text) is ambiguous  
- Requirements or acceptance criteria are incomplete  
- The preferred task granularity is unclear:
  - **coarse** (5â€“10 tasks)
  - **normal** (10â€“20 tasks)
  - **detailed** (20â€“40+ tasks)

---

## 8. Execution and auto-run behavior

You can be asked to:

- Automatically run through tasks sequentially
- Fetch the next available task
- Execute a single task
- Show a small dashboard of task progress

All of these rely on the `tasks` and `state` tables in `.taskmanager/taskmanager.db`.

### 8.1 Finding the next available task

A **task is considered "available"** if:

1. Its `status` is NOT one of: `'done'`, `'canceled'`, `'duplicate'`.
2. It is not archived (`archived_at IS NULL`).
3. All `dependencies` (if any) refer to tasks whose `status` is `'done'` or `'canceled'` or `'duplicate'`.
4. It is a **leaf task**, meaning:
   - It has no children in the `tasks` table, or
   - All of its children are in one of: `'done'`, `'canceled'`, `'duplicate'`.

SQL query for finding the next available task:

```sql
WITH done_ids AS (
  SELECT id FROM tasks WHERE status IN ('done', 'canceled', 'duplicate')
),
leaf_tasks AS (
  SELECT * FROM tasks t
  WHERE archived_at IS NULL
    AND status NOT IN ('done', 'canceled', 'duplicate', 'blocked')
    AND NOT EXISTS (SELECT 1 FROM tasks c WHERE c.parent_id = t.id)
)
SELECT * FROM leaf_tasks
WHERE dependencies IS NULL
   OR NOT EXISTS (
     SELECT 1 FROM json_each(dependencies) d
     WHERE d.value NOT IN (SELECT id FROM done_ids)
   )
ORDER BY
  CASE priority WHEN 'critical' THEN 0 WHEN 'high' THEN 1 WHEN 'medium' THEN 2 ELSE 3 END,
  complexity_score,
  id
LIMIT 1;
```

Use this same logic for:
- Auto-run
- â€œNext taskâ€ command
- Single-task execution when no explicit ID is provided.

### 8.2 Updating task status at start and end

When beginning work on a **leaf** task:

- If current `status` is `'planned'`, `'draft'`, `'blocked'`, `'paused'`, or `'needs-review'`:
  - Set it to `'in-progress'`.
- If dependencies are not satisfied:
  - For auto-run flows, **skip this task** and find another candidate.
  - For single-task execution, use the AskUserQuestion tool to ask the user how to handle dependencies.

When finishing work on a **leaf** task:

- If implementation is successful:
  - Set `status` to `'done'`.
- If blocked by something external:
  - Set `status` to `'blocked'` and update any dependency-related notes/metadata.
- If intentionally abandoned:
  - Set `status` to `'canceled'`.

After updating a leaf task's status, you MUST:

- Recompute and update the status of all its ancestor tasks using the recursive CTE status propagation (see section 8.5).
- Commit the transaction to ensure consistency.

### 8.3 Updating state at start and end of a task

At the **start** of executing a task:

```sql
UPDATE state SET
  current_task_id = :task_id,
  current_step = 'execution',
  mode = :mode,  -- 'autonomous' or 'interactive'
  last_update = datetime('now')
WHERE id = 1;
```

At the **end** of executing a task:

```sql
UPDATE state SET
  current_task_id = NULL,
  current_step = CASE WHEN :has_more_work THEN 'idle' ELSE 'done' END,
  last_update = datetime('now')
WHERE id = 1;
```

Log the decision to the decisions.log file for audit trail.

### 8.4 Handling dependencies for single-task execution

When asked to execute a specific task by ID:

1. Look up the task.
2. If any `dependencies` refer to tasks that are not `"done"`, `"canceled"`, or `"duplicate"`:
   - Use the AskUserQuestion tool to ask the user how to proceed, offering options like:
     - â€œMark all dependencies as done and continueâ€
     - â€œOpen and execute a dependency firstâ€
     - â€œAbort this task for nowâ€
3. Apply the userâ€™s decision and then proceed with status + state updates as above.

### 8.5 Status propagation is mandatory for any status change

Whenever this skill (or any command calling it) changes the status of **any task**, you MUST enforce the parent/child macro-status rules:

- Only **leaf tasks** (no children, or all children terminal) may have their status set directly by execution or user command.
- Any task with children in the `tasks` table is a **parent task** and its status is **always derived** from its direct children.
- You MUST NOT set a parent's status independently of its children.

**Recursive CTE Status Propagation:**

After updating a leaf task's status, use this recursive CTE to propagate status to all ancestors:

```sql
-- After updating a leaf task's status, propagate to ancestors
WITH RECURSIVE ancestors AS (
    -- Start with the parent of the updated task
    SELECT parent_id as id FROM tasks WHERE id = :task_id AND parent_id IS NOT NULL
    UNION ALL
    -- Recursively get all ancestors
    SELECT t.parent_id FROM tasks t JOIN ancestors a ON t.id = a.id WHERE t.parent_id IS NOT NULL
)
UPDATE tasks SET
    status = (
        SELECT CASE
            -- Any child in-progress -> parent is in-progress
            WHEN EXISTS(SELECT 1 FROM tasks c WHERE c.parent_id = tasks.id AND c.status = 'in-progress')
                THEN 'in-progress'
            -- Any child blocked -> parent is blocked
            WHEN EXISTS(SELECT 1 FROM tasks c WHERE c.parent_id = tasks.id AND c.status = 'blocked')
                THEN 'blocked'
            -- Any child needs-review -> parent is needs-review
            WHEN EXISTS(SELECT 1 FROM tasks c WHERE c.parent_id = tasks.id AND c.status = 'needs-review')
                THEN 'needs-review'
            -- Any child not terminal -> parent is planned
            WHEN EXISTS(SELECT 1 FROM tasks c WHERE c.parent_id = tasks.id AND c.status IN ('planned','draft','paused'))
                THEN 'planned'
            -- All children terminal with at least one done -> parent is done
            WHEN NOT EXISTS(SELECT 1 FROM tasks c WHERE c.parent_id = tasks.id AND c.status NOT IN ('done','canceled','duplicate'))
                THEN 'done'
            -- All children canceled/duplicate -> parent is canceled
            ELSE 'canceled'
        END
    ),
    updated_at = datetime('now')
WHERE id IN (SELECT id FROM ancestors);
```

This guarantees:

- If any child is in progress, its parent is **also** `'in-progress'`.
- If children are blocked, the parent shows `'blocked'`.
- If everything under a parent is finished, the parent is `'done'` or `'canceled'` as a macro view of the subtree.

### 8.6 Parent/child status propagation (macro status)

A task with one or more children is a **parent task**. For parent tasks:

- Their `status` is a **macro status derived from their direct children**.
- You MUST NOT set a parent's status independently of its children.
- Whenever any child's status changes, you MUST recompute the status of:
  - Its direct parent, and
  - All ancestors up to the root.

**Status precedence rules (highest to lowest):**

1. `'in-progress'` - Any child is actively being worked on
2. `'blocked'` - Any child is blocked (and none are in-progress)
3. `'needs-review'` - Any child needs review (and none are in-progress/blocked)
4. `'planned'` - Any child is not started (and none are in-progress/blocked/needs-review)
5. `'done'` - All children are terminal with at least one done
6. `'canceled'` - All children are canceled/duplicate

You MUST always perform this propagation after:

- Changing the status of any leaf or intermediate task.
- Adding or removing children from a parent.
- Bulk operations that change multiple child statuses.

### 8.7 Archival on terminal status

When a task reaches a **terminal status** (`'done'`, `'canceled'`, `'duplicate'`), you MAY archive it to reduce query result sizes. With SQLite, archival is simpler - tasks remain in the same table but are marked with an `archived_at` timestamp.

#### 8.7.1 When to archive

A task is eligible for archival when:

1. Its status is terminal (`'done'`, `'canceled'`, or `'duplicate'`).
2. For **leaf tasks** (no children or all children terminal): Archive immediately.
3. For **parent tasks**: Archive only when ALL direct children are already archived or terminal.

#### 8.7.2 Archival procedure

Archival is a simple UPDATE operation:

```sql
-- Archive a task
UPDATE tasks SET
  archived_at = datetime('now'),
  updated_at = datetime('now')
WHERE id = :task_id;
```

#### 8.7.3 Cascading archival

After archiving a leaf task, cascade to ancestors:

```sql
-- Archive parent if all children are archived
WITH RECURSIVE ancestors AS (
    SELECT parent_id as id FROM tasks WHERE id = :task_id AND parent_id IS NOT NULL
    UNION ALL
    SELECT t.parent_id FROM tasks t JOIN ancestors a ON t.id = a.id WHERE t.parent_id IS NOT NULL
)
UPDATE tasks SET
  archived_at = datetime('now'),
  updated_at = datetime('now')
WHERE id IN (SELECT id FROM ancestors)
  AND status IN ('done', 'canceled', 'duplicate')
  AND NOT EXISTS (
    SELECT 1 FROM tasks c
    WHERE c.parent_id = tasks.id AND c.archived_at IS NULL
  );
```

#### 8.7.4 Querying active vs archived tasks

```sql
-- Get only active (non-archived) tasks
SELECT * FROM tasks WHERE archived_at IS NULL;

-- Get only archived tasks
SELECT * FROM tasks WHERE archived_at IS NOT NULL;

-- Get all tasks regardless of archival status
SELECT * FROM tasks;
```

#### 8.7.5 Un-archiving (restoring tasks)

When a task needs to be reopened:

```sql
-- Restore a task from archive
UPDATE tasks SET
  archived_at = NULL,
  status = :new_status,
  updated_at = datetime('now')
WHERE id = :task_id;
```

After restoring, run status propagation for ancestors.

---

## 9. Memory Integration During Execution

This section describes how the Task Manager integrates with the `taskmanager-memory` skill during task execution.

### 9.1 Pre-Execution Memory Loading

Before starting **ANY** task (whether via `/execute-task`, `/run-tasks`, or any other execution flow):

1. **Load global memories**:
   ```sql
   -- Query relevant active memories
   SELECT * FROM memories
   WHERE status = 'active'
     AND (
       importance >= 3
       OR id IN (SELECT rowid FROM memories_fts WHERE memories_fts MATCH :search_terms)
       OR EXISTS (
         SELECT 1 FROM json_each(scope)
         WHERE json_each.key = 'tasks' AND json_each.value LIKE '%' || :task_id || '%'
       )
     )
   ORDER BY importance DESC, use_count DESC;
   ```

2. **Load task-scoped memories**:
   Query the `state` table's task_memory JSON column for entries matching current task or `'*'`.

3. **Run conflict detection**:
   - For each loaded memory, run the conflict detection algorithm (see `taskmanager-memory` skill, section 7).
   - If conflicts are detected, follow the conflict resolution workflow.

4. **Display memory summary**:
   - Show a brief summary of relevant memories:
     ```
     ðŸ“‹ Applying memories:
     - [M-0001] Always use Pest for tests (importance: 5)
     - [M-0003] API endpoints must validate input (importance: 4)
     - [Task] Focus on error handling (from --task-memory)
     ```

5. **Track applied memories**:
   ```sql
   -- Update memory usage tracking
   UPDATE memories SET
     use_count = use_count + 1,
     last_used_at = datetime('now'),
     updated_at = datetime('now')
   WHERE id IN (:applied_memory_ids);
   ```

### 9.2 Memory Application During Execution

While executing the task:

- Treat loaded memories as **hard constraints** for implementation decisions.
- If the task requires violating a memory (e.g., refactoring away from a pattern), this is a conflict and must be resolved.
- When making significant decisions during execution, consider whether they should become new memories.

### 9.3 Post-Execution Memory Review

Before marking a task as **"done"**:

1. **Run conflict detection again**:
   - Check if any implementation changes conflict with loaded memories.
   - Resolve conflicts before proceeding.

2. **Review task-scoped memories** (if any exist):
   - Ask the user: "Should any task memories be promoted to global memory?"
   - For each task memory, options:
     - "Promote to global memory" â†’ Insert new entry in the `memories` table.
     - "Discard" â†’ Remove from `taskMemory[]`.
   - Clear task memories for this task from the `state` table's task_memory column.

3. **Consider new memories**:
   - If significant decisions were made during execution (architectural choices, conventions, constraints discovered), prompt:
     > "Would you like to create a memory for any decisions made during this task?"

4. **Update memory tracking**:
   - Finalize `use_count` and `last_used_at` for all applied memories.
   - Clear the applied_memories column in the `state` table.

### 9.4 Memory Arguments for Commands

Commands that execute tasks (`execute-task`, `run-tasks`) support memory arguments:

**`--memory "description"`** (or `--global-memory`, `-gm`)
- Creates a **global memory** in the `memories` table immediately.
- Memory applies to the current task AND all future tasks.
- Sets `source.type = "user"`, `source.via = "<command-name>"`.

**`--task-memory "description"`** (or `-tm`)
- Creates a **task-scoped memory** in the `state` table's task_memory column.
- Memory applies only to the current task (or current batch for `/run-tasks`).
- Reviewed for promotion at task completion.

Argument parsing:

```
/execute-task 1.2.3 --memory "Always validate inputs"
/execute-task 1.2.3 -gm "Always validate inputs"

/execute-task 1.2.3 --task-memory "Focus on error paths"
/execute-task 1.2.3 -tm "Focus on error paths"

/run-tasks 5 --memory "Use Pest for all tests" --task-memory "Sprint 3 context"
```

### 9.5 Memory Integration in Autonomous Mode

During `/run-tasks` (autonomous execution):

- **At batch start**:
  - Parse `--memory` and create global memory if provided.
  - Parse `--task-memory` and add to `taskMemory[]` with `taskId = "*"` (applies to all tasks in batch).

- **Per-task iteration**:
  - Load relevant global memories.
  - Load task memories where `taskId` matches or is `"*"`.
  - Run conflict detection.
  - Execute task.
  - Run post-execution conflict detection.
  - Review task-specific memories (but defer `"*"` memories until batch end).

- **At batch end**:
  - Review `"*"` task memories for promotion.
  - Present summary of any deferred conflicts.
  - Clear all task memories.

---

## 10. Logging Behavior

This skill MUST write to the log files under `.taskmanager/logs/` during all operations.

### 10.1 Log Entry Format

All log entries follow the format:
```text
<ISO-timestamp> [<LEVEL>] [<session-id>] <message>
```

Where:
- `<ISO-timestamp>` is the current time in ISO 8601 format (UTC)
- `<LEVEL>` is one of: `ERROR`, `DECISION`, `DEBUG`
- `<session-id>` is from the `state` table's `logging_session_id` column (or `no-session` if not set)

### 10.2 When to Log

**errors.log** â€” ALWAYS append when:
- SQL query fails
- Database integrity errors occur
- File read/write errors occur
- Memory conflicts are detected
- Dependency cycles or resolution failures occur
- Any unexpected error state

Example:
```text
2025-12-11T10:00:00Z [ERROR] [sess-20251211100000] SQL error: no such table: tasks
2025-12-11T10:00:01Z [ERROR] [sess-20251211100000] Memory conflict: M-0001 references non-existent file app/OldService.php
```

**decisions.log** â€” ALWAYS append when:
- Tasks are created during planning
- Task status changes (planned â†’ in-progress â†’ done)
- Memories are created, updated, deprecated, or superseded
- Memories are applied to a task
- Conflict resolutions are made
- Batch operations start or complete

Example:
```text
2025-12-11T10:00:00Z [DECISION] [sess-20251211100000] Created 5 top-level tasks from PRD
2025-12-11T10:01:00Z [DECISION] [sess-20251211100000] Task 1.2.3 status: planned â†’ in-progress
2025-12-11T10:01:01Z [DECISION] [sess-20251211100000] Applied memories to task 1.2.3: M-0001, M-0003
2025-12-11T10:05:00Z [DECISION] [sess-20251211100000] Task 1.2.3 status: in-progress â†’ done
2025-12-11T10:05:01Z [DECISION] [sess-20251211100000] Task memory promoted to global: M-0004
```

**debug.log** â€” ONLY append when `logging_debug_enabled = 1` in the state table:
- Full task tree dumps
- Memory matching algorithm details
- Conflict detection steps
- File existence checks
- Intermediate computation states

Example:
```text
2025-12-11T10:00:00Z [DEBUG] [sess-20251211100000] Loaded task tree: 15 total tasks, 8 pending, 5 done
2025-12-11T10:00:01Z [DEBUG] [sess-20251211100000] Memory matching for task 1.2.3: checking 12 active memories
2025-12-11T10:00:02Z [DEBUG] [sess-20251211100000] M-0001 matched: scope.domains includes "auth"
2025-12-11T10:00:03Z [DEBUG] [sess-20251211100000] M-0002 skipped: scope.files don't overlap
```

### 10.3 Debug Mode

Debug logging is controlled by the `state` table's `logging_debug_enabled` column.

When a command includes `--debug` or `-d`:
1. Set `logging_debug_enabled = 1` in the state table
2. Generate a unique `logging_session_id` using timestamp: `sess-$(date +%Y%m%d%H%M%S)` (e.g., `sess-20251212103045`)
3. Write verbose debug information to `debug.log`
4. At command completion, reset `logging_debug_enabled = 0`

### 10.4 Logging Helper Pattern

When implementing logging, use this pattern:

```
1. Query the state table to get logging config
2. Determine if debug is enabled (logging_debug_enabled = 1)
3. For errors: ALWAYS append to errors.log
4. For decisions: ALWAYS append to decisions.log
5. For debug info: ONLY append to debug.log if logging_debug_enabled = 1
6. Use Edit tool to append (not Write, to preserve existing content)
```

### 10.5 Session ID Generation

When starting a command session:
1. Generate ID using bash timestamp: `sess-$(date +%Y%m%d%H%M%S)` (e.g., `sess-20251212103045`)
2. Store in the `state` table's `logging_session_id` column
3. Include in all log entries for correlation

---

## 11. SQLite-Specific Commands

These commands are specific to the SQLite storage backend:

### 11.1 taskmanager:sync

Two-way synchronization with Claude Code's native task system.

```
taskmanager:sync [--direction <to_native|from_native|both>] [--dry-run]
```

**Options:**
- `--direction to_native` - Push taskmanager tasks to native Claude Code tasks
- `--direction from_native` - Pull native Claude Code tasks into taskmanager
- `--direction both` (default) - Bidirectional sync
- `--dry-run` - Show what would be synced without making changes

**Sync behavior:**
- Maps taskmanager task IDs to native task UUIDs via `sync_log` table
- Preserves task status, priority, and completion state
- Handles conflicts by preferring the most recently updated version

### 11.2 taskmanager:export

Export SQLite database to JSON format for inspection, sharing, or backup.

```
taskmanager:export [--output <path>] [--format <json|pretty>] [--include-archived]
```

**Options:**
- `--output <path>` - Output file path (default: `.taskmanager/export.json`)
- `--format pretty` (default) - Human-readable indented JSON
- `--format json` - Compact single-line JSON
- `--include-archived` - Include archived tasks in export

**Export structure:**
```json
{
  "version": "2.0.0",
  "exportedAt": "2025-01-27T12:00:00Z",
  "tasks": [...],
  "memories": [...],
  "state": {...}
}
```

### 11.3 taskmanager:rollback

Revert from SQLite back to JSON format using the v1 backup.

```
taskmanager:rollback [--force]
```

**Options:**
- `--force` - Skip confirmation prompt

**Rollback procedure:**
1. Verifies `.taskmanager/backup-v1/` exists with valid JSON files
2. Prompts for confirmation (unless `--force`)
3. Backs up current SQLite database
4. Restores JSON files from backup-v1
5. Removes the SQLite database

**Warning:** This is a destructive operation. Any changes made after migration to SQLite will be lost unless you first run `taskmanager:export`.

---

## 12. Migration from JSON to SQLite

If you have an existing `.taskmanager/` directory with JSON files, the `taskmanager:init` command will automatically detect and migrate the data.

### 12.1 Automatic Migration

When `taskmanager:init` detects existing JSON files:

1. Creates backup in `.taskmanager/backup-v1/`
2. Creates new SQLite database
3. Migrates tasks from `tasks.json` (including archived tasks from `tasks-archive.json`)
4. Migrates memories from `memories.json`
5. Migrates state from `state.json`
6. Removes old JSON files (backup preserved)

### 12.2 Manual Migration

You can also run the migration script directly:

```bash
bash .taskmanager/scripts/migrate-v1-to-v2.sh
```

### 12.3 Verifying Migration

After migration, verify data integrity:

```bash
# Check task counts
sqlite3 .taskmanager/taskmanager.db "SELECT COUNT(*) FROM tasks"

# Check memory counts
sqlite3 .taskmanager/taskmanager.db "SELECT COUNT(*) FROM memories"

# Verify FTS index
sqlite3 .taskmanager/taskmanager.db "SELECT COUNT(*) FROM memories_fts"
```

---

## Examples

### Planning from text input

User prompt:

> â€œCreate a React app with a counter button that increments by 1 every click.â€

You interpret this as PRD content.

### Planning from file

User input:

> `taskmanager:plan docs/new-feature-prd.md`

You:

- Read the file  
- Parse PRD  
- Create tasks **level-by-level**  

See `PRD-INGEST-EXAMPLES.md` for reference.
