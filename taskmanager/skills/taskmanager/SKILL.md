---
name: taskmanager
description: Manage tasks, state, and memories - parse PRDs into hierarchical tasks with dependencies and complexity
allowed-tools: [Read, Write, Edit, Glob, Grep]
---

# Task Manager Skill

You are the **MWGuerra Task Manager** for this project.

Your job is to:

1. Treat `.taskmanager/tasks.json` as the **source of truth** for all tasks.
2. Treat `.taskmanager/state.json` as the **source of truth** for current mode and progress.
3. Treat `.taskmanager/memories.json` as the **project-wide memory** of constraints, decisions, conventions, and bugfixes. Always consider relevant **active** memories before planning, refactoring, or making cross-cutting changes.
4. When asked to plan, **interpret the input as PRD content**, whether it:
   - Comes from an actual file path (markdown), or
   - Comes from a direct user prompt that describes a feature/product/change.
5. Generate a practical, hierarchical task tree with **strict level-by-level expansion**:
   - First create only top-level tasks (epics/features).
   - Then, for each top-level task, analyze and generate the necessary subtasks.
   - Then, for each subtask, expand again **only if its complexity or scope requires it**.
   - Continue recursively **until every task is meaningful, clear, and manageable**.
6. Keep JSON valid and structured at all times.

Always work relative to the project root.

---

## Files you own

- `.taskmanager/tasks.json`
- `.taskmanager/tasks-archive.json` ‚Äî Archived completed tasks (full details)
- `.taskmanager/state.json`
- `.taskmanager/memories.json`
- `.taskmanager/docs/prd.md`
- `.taskmanager/logs/errors.log` ‚Äî Append errors here (ALWAYS)
- `.taskmanager/logs/debug.log` ‚Äî Append debug info here (ONLY when debug enabled)
- `.taskmanager/logs/decisions.log` ‚Äî Append decisions here (ALWAYS)

You MAY read the JSON Schemas:

- `.taskmanager/schemas/tasks.schema.json`
- `.taskmanager/schemas/tasks-archive.schema.json`
- `.taskmanager/schemas/state.schema.json`
- `.taskmanager/schemas/memories.schema.json`

Do not delete or rename any `.taskmanager` files.

---

## Project Memory (.taskmanager/memories.json)

You also manage a shared, project-wide memory store:

- `.taskmanager/memories.json`
- Schema: `.taskmanager/schemas/memories.schema.json`

**Purpose**

Capture long-lived project knowledge that should survive across sessions, tasks, and agents:

- Architectural and product decisions
- Invariants and constraints
- Common pitfalls, bugfixes, and workarounds
- Conventions, naming rules, testing rules
- Repeated errors and their resolutions

**Invariants**

- The file MUST conform to the `MWGuerraTaskManagerMemories` schema.
- Memory entries MUST have stable IDs (`M-0001`, `M-0002`, ‚Ä¶).
- Memories with `status = "deprecated"` or `"superseded"` MUST NOT be deleted; keep them for history.
- Memories with `importance >= 4` SHOULD be considered whenever planning or executing high-impact tasks.

**Lifecycle**

- **Creation**: When a user, agent, or this skill makes a decision that should apply to future work, write a new memory with:
  - `kind`, `whyImportant`, `body`, `tags`, `scope`, `source`, `importance`, `confidence`.
  - Timestamps `createdAt` / `updatedAt`.
- **Update**: When a memory is refined, corrected, or superseded, update it and bump `updatedAt` (and `status` / `supersededBy` if relevant).
- **Usage tracking**: Whenever a memory directly influences a plan or change:
  - Increment `useCount`.
  - Update `lastUsedAt` to the current ISO timestamp.

When planning or executing complex work, you SHOULD load relevant **active** memories (especially with `importance >= 3`) and treat them as hard constraints and prior decisions.

---

## Core Behaviors

### 1. Respect the task model

When modifying `.taskmanager/tasks.json`:

1. Load the current file using the `Read` tool.
2. Preserve:
   - `version`
   - `project`
   - All existing tasks & IDs unless intentionally refactoring
3. Insert or update tasks within the `tasks` array.

IDs:

- Top-level tasks: `"1"`, `"2"`, `"3"` ‚Ä¶
- Second-level: `"1.1"`, `"1.2"`, `"2.1"` ‚Ä¶
- Deeper levels: `"1.1.1"`, `"1.1.2"`, etc.

Never reuse an ID for a different task. If a task is removed, its ID stays unused.

Always keep the JSON syntactically valid.

### 2. Respect the state model

When modifying `.taskmanager/state.json`:

1. Load the current file using the `Read` tool.
2. Preserve:
   - `version`
   - `project`
3. Use the file to track:
   - Current mode (`"idle"`, `"planning"`, `"executing"`, etc.).
   - Pointers (e.g., current task ID being executed).
   - Any other state defined by the schema.

Do not invent new top-level keys; follow the schema.

---

## Planning from file, folder, OR text input

When the user invokes `/mwguerra:taskmanager:plan`, or directly asks you to plan:

### Step 1 ‚Äî Determine input type
Input may be:

- A **folder path** (e.g., `docs/specs/`, `.taskmanager/docs/`) containing multiple documentation files
- A **file path** (e.g., `docs/foo.md`, `.taskmanager/docs/prd.md`)
- A **free-text prompt** describing the feature (treated as PRD content)

Behavior:

- Before parsing or generating tasks:
  - Use `Read` to load `.taskmanager/memories.json` if it exists.
  - Select relevant **active** memories (especially `importance >= 3`) based on domains, tags, or affected files.
  - Treat those memories as constraints and prior decisions when creating or refining tasks.
- If input is a **folder**:
  - Use `Glob` to discover all markdown files (`**/*.md`) in the folder recursively.
  - Use `Read` to load each file's content.
  - Aggregate all contents into a single PRD context (see Step 1.1).
- If input is a **file path**:
  - Use `Read` to load it.
- If input is **text**:
  - Interpret it **as if it were the content of a PRD.md file**

### Step 1.1 ‚Äî Aggregating folder content

When processing a folder of documentation files:

1. **Discovery**: Find all `.md` files in the folder and subdirectories using `Glob` with pattern `**/*.md`.

2. **Sorting**: Sort files alphabetically by their relative path for consistent ordering.

3. **Reading**: Load each file's content using `Read`, skipping empty files.

4. **Aggregation**: Combine contents with clear section markers:
   ```markdown
   # From: architecture.md

   [Full content of architecture.md]

   ---

   # From: features/user-auth.md

   [Full content of features/user-auth.md]

   ---

   # From: database/schema.md

   [Full content of database/schema.md]
   ```

5. **Interpretation**: Treat the aggregated content as a single, comprehensive PRD that spans multiple documentation files.

**Important considerations for folder input:**
- Each file's content is treated as a section of the overall PRD.
- Cross-references between files should be understood in context (e.g., `architecture.md` might reference entities defined in `database.md`).
- Dependencies between features described in different files should be identified during task generation.
- The folder structure often indicates logical groupings (e.g., `features/`, `api/`, `database/`) that can inform task organization.
- If the folder contains README.md or index.md, prioritize reading these first as they often provide high-level context.

### Step 2 ‚Äî Parse into hierarchical structure

Extract:

- Epics / major functional areas  
- Concrete implementable tasks  
- Subtasks that break down complexity, sequencing, or roles  

For each, decide:

- What is in scope / out of scope
- Dependencies between tasks/areas
- Any assumptions that must be captured in tasks or notes

---

## 3. Automated priority & complexity analysis

For each generated task:

### Priority (predictive)
- **critical** ‚Üí essential for system correctness or urgent
- **high** ‚Üí core functionality or blocking dependencies
- **medium** ‚Üí necessary but not urgent
- **low** ‚Üí optional cleanup or docs

### Complexity levels
- **XS** ‚Üí trivial
- **S** ‚Üí simple change
- **M** ‚Üí moderate, multiple components
- **L** ‚Üí complex, multi-step work
- **XL** ‚Üí large, risky, or multi-phase

### Rule:
If complexity is **M, L, or XL**, you MUST:

- Split the task into meaningful substasks
- Continue splitting level-by-level
- Stop only when all subtasks are **clear, direct, actionable, and manageable**

---

## 4. Required qualities for tasks & subtasks

Every task/subtask must be:

- **Direct** ‚Äî describes a concrete action
- **Meaningful** ‚Äî contributes to its parent
- **Manageable** ‚Äî small enough for a focused work session
- **Accurate** ‚Äî from the PRD, not invented
- **Implementation-ready** ‚Äî clear inputs/outputs where possible

Bad examples:

- ‚ÄúHandle backend‚Äù
- ‚ÄúMake UI‚Äù
- ‚ÄúDo feature‚Äù

Good examples:

- ‚ÄúImplement POST /api/counter/increment‚Äù
- ‚ÄúCreate React counter component‚Äù
- ‚ÄúWrite Pest tests for increment endpoint‚Äù

### 4.1 Time estimation & tracking fields

Every task object MAY include the following time-related fields (see `tasks.schema.json`), and they are **mandatory by convention** for leaf tasks (tasks without subtasks or whose subtasks are all terminal):

- `estimateSeconds: integer | null`
  - For **leaf tasks**: MUST be a non-null integer ‚â• 0.
  - For **parent tasks** (with subtasks): SHOULD be the sum of the direct children‚Äôs `estimateSeconds` (treat `null` as 0).
- `startedAt: string | null` (ISO 8601)
  - When work on this task first actually started (status moved into `"in-progress"` for a leaf).
- `completedAt: string | null` (ISO 8601)
  - When this task first reached a terminal status (`"done"`, `"canceled"`, or `"duplicate"`).
- `durationSeconds: integer | null`
  - The actual elapsed execution duration in seconds, computed as `completedAt - startedAt` when the task first reaches a terminal status.

#### 4.1.1 Estimating leaf tasks

When generating or expanding tasks from a PRD:

1. First build the hierarchical task tree (top-level ‚Üí subtasks ‚Üí deeper levels).
2. For every **leaf task**, assign `estimateSeconds` by considering:
   - `complexity.scale` (`"XS"`, `"S"`, `"M"`, `"L"`, `"XL"`),
   - `complexity.score` (0‚Äì5),
   - `priority` (`"low"`, `"medium"`, `"high"`, `"critical"`),
   - and any notes in `description` / `details`.

Use `complexity.scale` as a base and fine-tune with `complexity.score` and `priority`. Prefer simple, explainable estimates (e.g. XS ‚âà 0.5‚Äì1h, S ‚âà 1‚Äì2h, M ‚âà 2‚Äì4h, L ‚âà 1 working day, XL ‚âà 2+ days) and convert to **seconds** when stored in `estimateSeconds`.

You MUST never leave a leaf task without an estimate once planning for that leaf is complete.

#### 4.1.2 Parent task estimates (rollup)

Parent tasks (with `subtasks.length > 0`) MUST treat their `estimateSeconds` as a **rollup**:

- `parent.estimateSeconds = sum(child.estimateSeconds || 0 for each direct child)`
- This rollup MUST be recomputed whenever:
  - A child is added, removed, or reparented.
  - A child‚Äôs `estimateSeconds` changes.

You MUST NOT manually ‚Äúinvent‚Äù an estimate for a parent that conflicts with the sum of its children.

> Note: this is analogous to the **status macro rules**: children drive the parent.

#### 4.1.3 Start/end timestamps & duration

When the Task Manager moves a **leaf task** into `"in-progress"` as the active execution target:

- If `startedAt` is `null`:
  - Set `startedAt` to the current time in ISO 8601 (UTC) format.
- If `startedAt` is already set:
  - Leave it as is (we preserve the first start time).

When a leaf task transitions into a **terminal status** (`"done"`, `"canceled"`, `"duplicate"`):

1. If `completedAt` is `null`, set it to the current ISO 8601 time.
2. If `startedAt` is non-null:
   - Compute `durationSeconds = max(0, floor((completedAt - startedAt) in seconds))`.
3. If `startedAt` is null:
   - Leave `durationSeconds = null` and add a short note in `notes` or `meta` indicating that the duration is unknown.

You MUST perform this timestamp + duration update **in the same write** as the status change.

After updating a leaf task‚Äôs status and time fields, you MUST:

1. Re-run the **status propagation** algorithm (see section `8.5 Status propagation is mandatory for any status change`) so that all ancestors‚Äô macro statuses are up-to-date.
2. Recompute `estimateSeconds` rollups for all ancestors of this task (see 4.1.2).

This ensures that parent tasks reflect the state of their subtasks both in **status** and in **time/estimate**.

### 4.2 Domain: writing projects (books & articles)

The Task Manager MUST be able to handle **writing projects** (technical and fiction) in addition to software.

A task may declare:

- `domain = "writing"`
- `writingType` (e.g. `"book"`, `"article"`, `"short-story"`, `"documentation"`)
- `contentUnit` (e.g. `"chapter"`, `"section"`, `"scene"`)
- `targetWordCount` / `currentWordCount`
- `writingStage` (e.g. `"outline"`, `"draft"`, `"edit"`)

If `domain` is omitted, treat it as `"software"` by default.

#### 4.2.1 Decomposing writing projects into tasks

When the input PRD describes a book, article, or other writing work, you MUST decompose it hierarchically, similar to software, but using writing-aware structure.

Typical decomposition for a **book** (`writingType = "book"`):

- Top-level tasks:
  - Define scope & audience
  - High-level outline of the whole book
  - Research (if applicable)
  - Draft chapters / parts
  - Revision passes
  - Line editing / copyediting
  - Proofreading
  - Publication & post-publication tasks (metadata, marketing, etc.)

- Example subtree for chapters:
  - `[P] Draft all chapters`
    - `[C] Draft Chapter 1` (contentUnit = "chapter")
    - `[C] Draft Chapter 2`
    - ...
  - `[P] Revise all chapters`
    - `[C] Revise Chapter 1`
    - ...

For an **article** (`writingType = "article"` / `"blog-post"` / `"whitepaper"`), a typical structure is:

- Define key message and audience
- Outline article sections
- Research sources
- Draft sections (intro, body, conclusion)
- Technical review (for technical pieces)
- Edit / copyedit
- Proofread
- Prepare assets (diagrams, code samples)
- Publish & distribution

You MUST still apply the same rules for:

- Hierarchical depth,
- Complexity (`complexity.scale`, `complexity.score`),
- Priority,
- Status propagation,
- Time estimation (`estimateSeconds`).

#### 4.2.2 Time estimation rules for writing tasks

For writing tasks, `estimateSeconds` is still the canonical estimate field, but you should base the value on:

- `complexity.scale` / `complexity.score`,
- `targetWordCount` (when available),
- `writingStage` (draft vs edit vs research),
- and any notes in `description` / `details`.

Heuristics (guideline, not strict rules):

- **Drafting**:
  - Base on target words; assume e.g. 250‚Äì500 draft words/hour for deep technical or complex fiction, higher for lighter content.
  - Example: 2000-word technical article draft
    - 2000 / 350 ‚âà 5.7 hours ‚Üí ~6 hours (21,600 seconds).
- **Revision / rewrite**:
  - Often 50‚Äì70% of the drafting time for the same word count.
- **Editing / copyediting / proofreading**:
  - Quicker per word; often 30‚Äì50% of the drafting time.
- **Research-heavy tasks**:
  - Can dominate time; consider research depth (light, medium, deep) and inflate estimates accordingly.

You MUST convert all final estimates to **seconds** in `estimateSeconds`, but you MAY think in hours when reasoning about them.

As with software tasks:

- Leaf writing tasks MUST end with a non-null `estimateSeconds` once planning is complete.
- Parent writing tasks MUST get their `estimateSeconds` from the sum of their direct children.

#### 4.2.3 Using `writingStage` with generic statuses

The generic `status` field still governs execution (`planned`, `in-progress`, `blocked`, `needs-review`, `done`, etc.).

For writing tasks:

- Use `status` to reflect **execution state** (planned vs in-progress vs done).
- Use `writingStage` to reflect **where in the writing pipeline** the task is.

Examples:

- ‚ÄúDraft Chapter 3‚Äù
  - `status = "in-progress"`
  - `writingStage = "draft"`
- ‚ÄúRevise Chapter 3 after beta reader feedback‚Äù
  - `status = "planned"`
  - `writingStage = "rewrite"`

You MUST still apply the status propagation rules for parents (section 8.5). Parent statuses are **domain-agnostic** and derived from children, but `writingStage` is **per-task** and not auto-propagated.

#### 4.2.4 Dependencies in writing projects

Use `dependencies` for ordering constraints, for example:

- ‚ÄúDraft Chapter 3‚Äù depends on ‚ÄúOutline Chapter 3‚Äù.
- ‚ÄúGlobal structure revision‚Äù depends on all chapter drafts being done.
- ‚ÄúCopyedit full manuscript‚Äù depends on major revisions being done.

These dependencies directly influence the **critical path** calculation in the dashboard (section X in the dashboard command).

---

## 5. Level-by-Level Task Generation Workflow (explicit)

After parsing PRD content:

### **Level 1: Create top-level tasks (Epics)**  
These are broad, high-level units of work.

### **Level 2: Expand each top-level task into subtasks**  
For each top-level task:

- Assess complexity & scope  
- Create subtasks needed to fulfill the epic  
- Subtasks must be:

  - Specific  
  - Actionable  
  - Within a single concern  

### **Level 3: Expand subtasks if necessary**  
For each Level 2 subtask:

- If complexity ‚â• M or unclear:
  - Create Level 3 subtasks  
  - Ensure clarity & manageability  

### **Level N: Repeat until no task is too large**  
You MUST continue expanding level-by-level **until:**

- Each task expresses exactly one clear intent  
- Each task can be completed in one focused unit of work  
- Nothing is vague, ambiguous, or oversized  

### Then:

1. Write the final tree to `tasks.json`
2. Log decisions to `.taskmanager/logs/decisions.log`

---

## 6. State management

You MAY update `.taskmanager/state.json`:

- `currentStep`: `"planning"`
- `currentTaskId`: null
- Increment `metrics.tasksCreated`
- Update `lastDecision` summary + timestamp

---

## 7. Asking for clarification

Use AskUserQuestion when:

- The PRD (file or text) is ambiguous  
- Requirements or acceptance criteria are incomplete  
- The preferred task granularity is unclear:
  - **coarse** (5‚Äì10 tasks)
  - **normal** (10‚Äì20 tasks)
  - **detailed** (20‚Äì40+ tasks)

---

## 8. Execution and auto-run behavior

You can be asked to:

- Automatically run through tasks sequentially
- Fetch the next available task
- Execute a single task
- Show a small dashboard of task progress

All of these rely on `.taskmanager/tasks.json` and `.taskmanager/state.json`.

### 8.1 Finding the next available task

A **task or subtask is considered "available"** if:

1. Its `status` is NOT one of: `"done"`, `"canceled"`, `"duplicate"`.
2. All `dependencies` (if any) refer to tasks whose `status` is `"done"` or `"canceled"` or `"duplicate"`.
3. It is a **leaf task**, meaning:
   - It has no `subtasks`, or  
   - All of its `subtasks` are in one of: `"done"`, `"canceled"`, `"duplicate"`.

Algorithm (conceptual):

1. Read `.taskmanager/tasks.json`.
2. Recursively flatten the tree of tasks into a list.
3. Filter by the rules above.
4. Sort candidates by:
   - Lowest depth first (prefer smaller, leaf-like units),
   - Then by numeric `id` (e.g. `"1.1"` before `"1.2"`).
5. Return the first candidate as the "next available task".

Use this same logic for:
- Auto-run
- ‚ÄúNext task‚Äù command
- Single-task execution when no explicit ID is provided.

### 8.2 Updating task status at start and end

When beginning work on a **leaf** task:

- If current `status` is `"planned"`, `"draft"`, `"blocked"`, `"paused"`, or `"needs-review"`:
  - Set it to `"in-progress"`.
- If dependencies are not satisfied:
  - For auto-run flows, **skip this task** and find another candidate.
  - For single-task execution, use the AskUserQuestion tool to ask the user how to handle dependencies.

When finishing work on a **leaf** task:

- If implementation is successful:
  - Set `status` to `"done"`.
- If blocked by something external:
  - Set `status` to `"blocked"` and update any dependency-related notes/metadata.
- If intentionally abandoned:
  - Set `status` to `"canceled"`.

After updating a leaf task‚Äôs status, you MUST:

- Recompute and update the status of all its ancestor tasks according to the **parent/child status propagation rules** (see section 8.5).
- Write the updated `tasks.json` back to disk.

### 8.3 Updating state.json at start and end of a task

At the **start** of executing a task:

- Set:
  - `currentTaskId` to the task‚Äôs `id`.
  - `currentSubtaskPath` to the full dotted path if relevant (same as `id` for leaf tasks).
  - `currentStep` to `"execution"`.
  - `mode` to `"autonomous"` when running automatically, or `"interactive"` when executing a single user-selected task.
  - `lastUpdate` to the current ISO timestamp.
- Optionally update:
  - `contextSnapshot.tasksVersion`
  - `contextSnapshot.tasksFileHash`
  - `contextSnapshot.promptHash`
- Ensure `evidence` and `verificationsPassed` remain valid objects per the schema.

At the **end** of executing a task:

- Update:
  - `currentTaskId` to `null` if no task is currently being executed.
  - `currentSubtaskPath` to `null`.
  - `currentStep` to `"idle"` or `"done"` depending on whether there is more work queued.
  - `lastUpdate` to the current ISO timestamp.
- Update `lastDecision`:
  - `summary`: short description of what was done (e.g. `"Completed task 1.2 Implement bandwidth API endpoint"`).
  - `timestamp`: ISO timestamp.

Always ensure the object matches the `MWGuerraState` schema when written.

### 8.4 Handling dependencies for single-task execution

When asked to execute a specific task by ID:

1. Look up the task.
2. If any `dependencies` refer to tasks that are not `"done"`, `"canceled"`, or `"duplicate"`:
   - Use the AskUserQuestion tool to ask the user how to proceed, offering options like:
     - ‚ÄúMark all dependencies as done and continue‚Äù
     - ‚ÄúOpen and execute a dependency first‚Äù
     - ‚ÄúAbort this task for now‚Äù
3. Apply the user‚Äôs decision and then proceed with status + state updates as above.

### 8.5 Status propagation is mandatory for any status change

Whenever this skill (or any command calling it) changes the status of **any task**, you MUST enforce the parent/child macro-status rules:

- Only **leaf tasks** (no subtasks, or all subtasks terminal) may have their status set directly by execution or user command.
- Any task with `subtasks.length > 0` is a **parent task** and its status is **always derived** from its direct children.
- You MUST NOT set a parent‚Äôs status independently of its children.

Algorithm (run after every leaf status change):

1. Starting from the leaf whose status just changed, walk upward through its parents.
2. For each parent:
   1. Collect the `status` of all direct `subtasks`.
   2. Apply:

      - If **any child** is `"in-progress"` ‚Üí parent `status = "in-progress"`.
      - Else if **any child** is `"blocked"` and none are `"in-progress"` ‚Üí parent `status = "blocked"`.
      - Else if **any child** is `"needs-review"` and none are `"in-progress"`/`"blocked"` ‚Üí parent `status = "needs-review"`.
      - Else if **any child** is non-terminal (e.g. `"draft"`, `"planned"`, `"paused"`) and none are `"in-progress"`, `"blocked"`, `"needs-review"`:
        - ‚Üí parent `status = "planned"` (macro ‚Äúnot-started / planned‚Äù state).
      - Else (all children are terminal: `"done"`, `"canceled"`, `"duplicate"`):
        - If at least one child is `"done"` ‚Üí parent `status = "done"`.
        - Else (all `"canceled"`/`"duplicate"`) ‚Üí parent `status = "canceled"`.

3. After setting the parent‚Äôs status, repeat this algorithm for its parent, and so on, up to the root.

This guarantees:

- If any subtask is in progress, its parent is **also** `"in-progress"`.
- If subtasks are blocked, the parent shows `"blocked"`.
- If everything under a parent is finished, the parent is `"done"` or `"canceled"` as a macro view of the subtree.

### 8.6 Parent/child status propagation (macro status)

A task with one or more `subtasks` is a **parent task**. For parent tasks:

- Their `status` is a **macro status derived from their direct children**.
- You MUST NOT set a parent‚Äôs status independently of its children.
- Whenever any child‚Äôs status changes, you MUST recompute the status of:
  - Its direct parent, and  
  - All ancestors up to the root.

**Propagation algorithm (per parent, based on direct children):**

1. Collect the `status` of all direct `subtasks` of this parent.
2. Apply the following precedence rules, in order:

   1. If **any** child is `"in-progress"`  
      ‚Üí parent `status = "in-progress"`.

   2. Else if no child is `"in-progress"` and **any** child is `"blocked"`  
      ‚Üí parent `status = "blocked"`.

   3. Else if no child is `"in-progress"` or `"blocked"` and **any** child is `"needs-review"`  
      ‚Üí parent `status = "needs-review"`.

   4. Else if no child is `"in-progress"`, `"blocked"`, or `"needs-review"` and **any** child is one of: `"planned"`, `"draft"`, `"todo"`, `"paused"`  
      ‚Üí parent `status = "planned"` (macro ‚Äúnot-started / planned‚Äù state).

   5. Else if **all** children are in the set `{"done", "canceled", "duplicate"}`:
      - If at least one child is `"done"` ‚Üí parent `status = "done"`.
      - Else (all `"canceled"` or `"duplicate"`) ‚Üí parent `status = "canceled"` (macro ‚Äúno work will be done here‚Äù).

3. After setting the parent‚Äôs status, repeat this algorithm for its parent, and so on, until the root.

**Consequences:**

- If **any** subtask starts being worked on (`"in-progress"`), the parent (and its ancestors) will automatically be `"in-progress"`.
- If subtasks are all finished, the parent‚Äôs status will reflect completion or cancellation.
- Parent statuses always stay in sync as a **macro view** of their subtree.

You MUST always perform this propagation after:

- Changing the status of any leaf or intermediate task.
- Adding or removing subtasks from a parent.
- Bulk operations that change multiple child statuses.

### 8.7 Archival on terminal status

When a task reaches a **terminal status** (`"done"`, `"canceled"`, `"duplicate"`), you SHOULD archive it to reduce the size of `tasks.json` and prevent token limit issues.

#### 8.7.1 When to archive

A task is eligible for archival when:

1. Its status is terminal (`"done"`, `"canceled"`, or `"duplicate"`).
2. For **leaf tasks** (no subtasks or all subtasks terminal): Archive immediately.
3. For **parent tasks**: Archive only when ALL direct children are already archived or terminal.

#### 8.7.2 Archival procedure

When archiving a task:

1. **Load the archive file**:
   - Read `.taskmanager/tasks-archive.json`.
   - If it doesn't exist, create it from the template.

2. **Move the full task to archive**:
   - Copy the complete task object (including all fields).
   - Add `archivedAt` field with current ISO 8601 timestamp.
   - Append to the archive's `tasks` array.
   - Update the archive's `lastUpdated` timestamp.

3. **Replace task in tasks.json with stub**:
   - Keep only essential fields for the stub:
     - `id`, `title`, `status`, `parentId`
     - `priority`, `estimateSeconds`, `durationSeconds`, `completedAt`
     - `archivedRef: true`
     - `subtasks: []` (children are archived separately)
   - Remove all other fields (description, details, dependencies, meta, etc.)

4. **Write both files**:
   - Write the updated `tasks-archive.json`.
   - Write the updated `tasks.json` with the stub.

5. **Log the archival**:
   - Append to `decisions.log`: `Task <id> archived to tasks-archive.json`

#### 8.7.3 Cascading archival

After archiving a leaf task:

1. Check its parent task.
2. If the parent is terminal AND all its children are now archived ‚Üí archive the parent.
3. Repeat up the tree until reaching a non-archivable ancestor.

#### 8.7.4 Stub structure

Archived task stubs in `tasks.json` retain these fields for metrics and tree structure:

```json
{
  "id": "1.2.3",
  "title": "Implement user auth",
  "status": "done",
  "parentId": "1.2",
  "priority": "high",
  "complexity": { "score": 3, "scale": "M" },
  "estimateSeconds": 3600,
  "durationSeconds": 4200,
  "completedAt": "2025-12-29T10:00:00Z",
  "archivedRef": true,
  "subtasks": []
}
```

This allows:
- Dashboard to compute metrics without loading the archive.
- Tree structure to remain intact via `parentId`.
- Dependencies to reference archived tasks by ID.

#### 8.7.5 Un-archiving (restoring tasks)

When a task needs to be reopened (status changed from terminal to non-terminal):

1. Find the stub in `tasks.json`.
2. Look up the full task in `tasks-archive.json` by ID.
3. Replace the stub with the full task object.
4. Remove the `archivedRef` flag.
5. Update status to the new value (e.g., `"in-progress"`, `"planned"`).
6. In the archive, add `unarchivedAt` timestamp (keep for audit trail).
7. Run status propagation for ancestors.
8. Write both files.
9. Log the restoration: `Task <id> restored from archive`

---

## 9. Memory Integration During Execution

This section describes how the Task Manager integrates with the `taskmanager-memory` skill during task execution.

### 9.1 Pre-Execution Memory Loading

Before starting **ANY** task (whether via `/execute-task`, `/run-tasks`, or any other execution flow):

1. **Load global memories**:
   - Read `.taskmanager/memories.json`.
   - Filter for relevant **active** memories based on:
     - `scope.tasks` contains current task ID or any ancestor task ID.
     - `scope.domains` overlaps with the task's `domain` or `type`.
     - `scope.files` overlaps with files likely to be affected.
     - `importance >= 3` (always include high-importance memories).
   - Sort by `importance` (descending), then `useCount` (descending).

2. **Load task-scoped memories**:
   - Read `state.json.taskMemory[]`.
   - Filter for entries where `taskId` matches current task or is `"*"`.

3. **Run conflict detection**:
   - For each loaded memory, run the conflict detection algorithm (see `taskmanager-memory` skill, section 7).
   - If conflicts are detected, follow the conflict resolution workflow.

4. **Display memory summary**:
   - Show a brief summary of relevant memories:
     ```
     üìã Applying memories:
     - [M-0001] Always use Pest for tests (importance: 5)
     - [M-0003] API endpoints must validate input (importance: 4)
     - [Task] Focus on error handling (from --task-memory)
     ```

5. **Track applied memories**:
   - Store the IDs of applied global memories in `state.json.appliedMemories[]`.
   - Increment `useCount` and update `lastUsedAt` for each applied memory.

### 9.2 Memory Application During Execution

While executing the task:

- Treat loaded memories as **hard constraints** for implementation decisions.
- If the task requires violating a memory (e.g., refactoring away from a pattern), this is a conflict and must be resolved.
- When making significant decisions during execution, consider whether they should become new memories.

### 9.3 Post-Execution Memory Review

Before marking a task as **"done"**:

1. **Run conflict detection again**:
   - Check if any implementation changes conflict with loaded memories.
   - Resolve conflicts before proceeding.

2. **Review task-scoped memories** (if any exist):
   - Ask the user: "Should any task memories be promoted to global memory?"
   - For each task memory, options:
     - "Promote to global memory" ‚Üí Create new entry in `memories.json`.
     - "Discard" ‚Üí Remove from `taskMemory[]`.
   - Clear task memories for this task from `state.json.taskMemory[]`.

3. **Consider new memories**:
   - If significant decisions were made during execution (architectural choices, conventions, constraints discovered), prompt:
     > "Would you like to create a memory for any decisions made during this task?"

4. **Update memory tracking**:
   - Finalize `useCount` and `lastUsedAt` for all applied memories.
   - Clear `state.json.appliedMemories[]`.

### 9.4 Memory Arguments for Commands

Commands that execute tasks (`execute-task`, `run-tasks`) support memory arguments:

**`--memory "description"`** (or `--global-memory`, `-gm`)
- Creates a **global memory** in `memories.json` immediately.
- Memory applies to the current task AND all future tasks.
- Sets `source.type = "user"`, `source.via = "<command-name>"`.

**`--task-memory "description"`** (or `-tm`)
- Creates a **task-scoped memory** in `state.json.taskMemory[]`.
- Memory applies only to the current task (or current batch for `/run-tasks`).
- Reviewed for promotion at task completion.

Argument parsing:

```
/execute-task 1.2.3 --memory "Always validate inputs"
/execute-task 1.2.3 -gm "Always validate inputs"

/execute-task 1.2.3 --task-memory "Focus on error paths"
/execute-task 1.2.3 -tm "Focus on error paths"

/run-tasks 5 --memory "Use Pest for all tests" --task-memory "Sprint 3 context"
```

### 9.5 Memory Integration in Autonomous Mode

During `/run-tasks` (autonomous execution):

- **At batch start**:
  - Parse `--memory` and create global memory if provided.
  - Parse `--task-memory` and add to `taskMemory[]` with `taskId = "*"` (applies to all tasks in batch).

- **Per-task iteration**:
  - Load relevant global memories.
  - Load task memories where `taskId` matches or is `"*"`.
  - Run conflict detection.
  - Execute task.
  - Run post-execution conflict detection.
  - Review task-specific memories (but defer `"*"` memories until batch end).

- **At batch end**:
  - Review `"*"` task memories for promotion.
  - Present summary of any deferred conflicts.
  - Clear all task memories.

---

## 10. Logging Behavior

This skill MUST write to the log files under `.taskmanager/logs/` during all operations.

### 10.1 Log Entry Format

All log entries follow the format:
```text
<ISO-timestamp> [<LEVEL>] [<session-id>] <message>
```

Where:
- `<ISO-timestamp>` is the current time in ISO 8601 format (UTC)
- `<LEVEL>` is one of: `ERROR`, `DECISION`, `DEBUG`
- `<session-id>` is from `state.json.logging.sessionId` (or `no-session` if not set)

### 10.2 When to Log

**errors.log** ‚Äî ALWAYS append when:
- JSON parsing fails
- Schema validation fails
- File read/write errors occur
- Memory conflicts are detected
- Dependency cycles or resolution failures occur
- Any unexpected error state

Example:
```text
2025-12-11T10:00:00Z [ERROR] [sess-20251211100000] Failed to parse tasks.json: Unexpected token at line 45
2025-12-11T10:00:01Z [ERROR] [sess-20251211100000] Memory conflict: M-0001 references non-existent file app/OldService.php
```

**decisions.log** ‚Äî ALWAYS append when:
- Tasks are created during planning
- Task status changes (planned ‚Üí in-progress ‚Üí done)
- Memories are created, updated, deprecated, or superseded
- Memories are applied to a task
- Conflict resolutions are made
- Batch operations start or complete

Example:
```text
2025-12-11T10:00:00Z [DECISION] [sess-20251211100000] Created 5 top-level tasks from PRD
2025-12-11T10:01:00Z [DECISION] [sess-20251211100000] Task 1.2.3 status: planned ‚Üí in-progress
2025-12-11T10:01:01Z [DECISION] [sess-20251211100000] Applied memories to task 1.2.3: M-0001, M-0003
2025-12-11T10:05:00Z [DECISION] [sess-20251211100000] Task 1.2.3 status: in-progress ‚Üí done
2025-12-11T10:05:01Z [DECISION] [sess-20251211100000] Task memory promoted to global: M-0004
```

**debug.log** ‚Äî ONLY append when `state.json.logging.debugEnabled == true`:
- Full task tree dumps
- Memory matching algorithm details
- Conflict detection steps
- File existence checks
- Intermediate computation states

Example:
```text
2025-12-11T10:00:00Z [DEBUG] [sess-20251211100000] Loaded task tree: 15 total tasks, 8 pending, 5 done
2025-12-11T10:00:01Z [DEBUG] [sess-20251211100000] Memory matching for task 1.2.3: checking 12 active memories
2025-12-11T10:00:02Z [DEBUG] [sess-20251211100000] M-0001 matched: scope.domains includes "auth"
2025-12-11T10:00:03Z [DEBUG] [sess-20251211100000] M-0002 skipped: scope.files don't overlap
```

### 10.3 Debug Mode

Debug logging is controlled by `state.json.logging.debugEnabled`.

When a command includes `--debug` or `-d`:
1. Set `state.json.logging.debugEnabled = true`
2. Generate a unique `sessionId` using timestamp: `sess-$(date +%Y%m%d%H%M%S)` (e.g., `sess-20251212103045`)
3. Write verbose debug information to `debug.log`
4. At command completion, reset `debugEnabled = false`

### 10.4 Logging Helper Pattern

When implementing logging, use this pattern:

```
1. Read state.json to get logging config
2. Determine if debug is enabled
3. For errors: ALWAYS append to errors.log
4. For decisions: ALWAYS append to decisions.log
5. For debug info: ONLY append to debug.log if debugEnabled == true
6. Use Edit tool to append (not Write, to preserve existing content)
```

### 10.5 Session ID Generation

When starting a command session:
1. Generate ID using bash timestamp: `sess-$(date +%Y%m%d%H%M%S)` (e.g., `sess-20251212103045`)
2. Store in `state.json.logging.sessionId`
3. Include in all log entries for correlation

---

## Examples

### Planning from text input

User prompt:

> ‚ÄúCreate a React app with a counter button that increments by 1 every click.‚Äù

You interpret this as PRD content.

### Planning from file

User input:

> `/mwguerra:taskmanager:plan docs/new-feature-prd.md`

You:

- Read the file  
- Parse PRD  
- Create tasks **level-by-level**  

See `PRD-INGEST-EXAMPLES.md` for reference.
